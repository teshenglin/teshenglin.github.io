<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computational Mathematics | Te-Sheng Lin</title>
    <link>https://teshenglin.github.io/categories/computational-mathematics/</link>
      <atom:link href="https://teshenglin.github.io/categories/computational-mathematics/index.xml" rel="self" type="application/rss+xml" />
    <description>Computational Mathematics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 12 Jun 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://teshenglin.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Computational Mathematics</title>
      <link>https://teshenglin.github.io/categories/computational-mathematics/</link>
    </image>
    
    <item>
      <title>Lagrange Multiplier - 01</title>
      <link>https://teshenglin.github.io/post/2020_lagrange_multiplier/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://teshenglin.github.io/post/2020_lagrange_multiplier/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;在微積分課程裡我們有學到如何利用 Lagrange multiplier 來解 constraint optimization 問題. 這邊要介紹課本裡沒教的 Lagrangian function.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;goal-我們想要解以下這個問題&#34;&gt;Goal: 我們想要解以下這個問題&lt;/h4&gt;
&lt;p&gt;$$
\min_{x} f(x), \quad \text{subject to } \quad  g(x)=0.
$$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Observation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;微積分課本告訴我們一個相對好懂的直觀, 就是這個解會發生在兩個等高線相切的地方, 因此在這個問題的解那個點的位置, 兩個函數 $f$ 與 $g$ 等高線的法向量會平行, 因此可以列出以下兩個式子
$$
\partial_x f + \lambda \partial_x g = 0, \quad  g(x)=0.
$$
這裡我們引進一個新的未知數 $\lambda$, 即稱為 Lagrange multiplier.
因為有兩個方程式, 因此我們可以解出兩個未知數 $x$ 以及 $\lambda$.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;上列的這個方程組有另一種相對好記的方式, 就是引進所謂的 Lagrangian function
$$
L(x, \lambda) = f(x) + \lambda g(x)
$$
這是一個雙變數方程式, 而原本問題的解會發生在這個方程的 critical point, 也就是會滿足 $\nabla L=0$.&lt;/p&gt;
&lt;p&gt;要注意的是由於 $L$ 是個雙變數函數, 所以 $\nabla = (\partial_x, \partial_{\lambda})$. 根據這樣的定義我們將 $\nabla L=0$ 方程式列出來會得到跟上面一模一樣的兩個方程組.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark 1:&lt;/strong&gt;  $\partial_{x} L = \partial_x f + \lambda \partial_x g$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark 2:&lt;/strong&gt;  $\partial_{\lambda} L = g(x)$&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;引進 Lagrangian function 比較好記是因為假設我有更多的 constraints, 例如我想解以下這個問題:
$$
\min_{x} f(x), \quad \text{subject to } \quad  g_1(x)=0, \quad g_2(x)=0.
$$
要找一個函數最小值不過有兩個限制條件.&lt;/p&gt;
&lt;p&gt;這樣的話我們照之前的步驟, 先引進 Lagrangian function
$$
L(x, \lambda_1, \lambda_2) = f(x) + \lambda_1 g_1(x) + \lambda_2 g_2(x)
$$
然後原問題的最佳解會發生在 $\nabla L=0$.&lt;/p&gt;
&lt;p&gt;要注意的是這次的 $L$ 是個三變數函數, 所以 $\nabla L = (\partial_x, \partial_{\lambda_1}, \partial_{\lambda_2})$. 然後將 $\nabla L=0$ 寫下來就是
$$
\partial_x f + \lambda_1 \partial_x g_1 + \lambda_2 \partial_x g_2 = 0, \quad  g_1(x)=0, \quad g_2(x)=0.
$$
就得到我們需要解的方程組了!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;接著我們試著將以上寫的更廣義一點, 考慮一個 $n$ 維度的最佳化問題有 $m$ 個限制式, 我們引進一些符號: $\pmb{x}\in \mathbb{R}^n$,  $\pmb{g}(\pmb{x}):\mathbb{R}^n\to\mathbb{R}^m$, 這個有限制的最佳化問題即可寫成
$$
\min_{\pmb{x}\in\mathbb{R}^n}f(\pmb{x}), \quad \text{subject to } \quad  \pmb{g}(\pmb{x})=\pmb{0}.
$$&lt;/p&gt;
&lt;p&gt;我們接著引進 Lagrangian function
$$
L(\pmb{x}, \pmb{\lambda}) = f(\pmb{x}) + \pmb{\lambda}^T \pmb{g}(\pmb{x}), \quad \pmb{\lambda}\in\mathbb{R}^m
$$&lt;/p&gt;
&lt;p&gt;原問題的最佳解會發生在 $\nabla L=0$, 也就是 $(\nabla_{\pmb{x}} L, \nabla_{\pmb{\lambda}} L) = (0, 0)$, 也就是
$$
\nabla_{\pmb{x}} f(\pmb{x}) + \pmb{\lambda}^T \nabla_{\pmb{x}}\pmb{g}(\pmb{x}) = 0, \quad \pmb{g}(\pmb{x})=\pmb{0}.
$$&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;所以為什麼要引進 Lagrange multiplier 或是 Lagrangian function?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;引進 Lagrange multiplier 的好處是我們將一個&lt;strong&gt;最佳化問題&lt;/strong&gt;改寫成一個&lt;strong&gt;求根問題&lt;/strong&gt;. 理論上 $F(x)=0$ 這種問題不管線性或非線性我們都比較會解. 而最佳化問題就相對比較無從下手.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BUT&lt;/strong&gt;, 付出的代價是我們增加了維度! 原本 $n$ 維最小值問題變成 $n+m$ 維求根問題.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引進 Lagrangian function 最明顯的好處是&lt;strong&gt;比較好記&lt;/strong&gt;, 不管是&lt;code&gt;記&lt;/code&gt;在頭腦裡或是做筆&lt;code&gt;記&lt;/code&gt;寫下來. 整個問題很輕易的就記成 $\nabla L=0$.&lt;/p&gt;
&lt;p&gt;當然還有其他更重要的好處, 就是可以推導出所謂的 dual optimization problem: 
&lt;a href=&#34;https://teshenglin.github.io/post/2020_lagrange_multiplier_2&#34;&gt;Lagrange Multiplier - 02&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Lagrange Multiplier - 02</title>
      <link>https://teshenglin.github.io/post/2020_lagrange_multiplier_2/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://teshenglin.github.io/post/2020_lagrange_multiplier_2/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;這裡我們再多討論一點 Lagrangian function.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我們先看最簡單的一維問題, 求一個有限制式的函數最小值問題:
$$
\min_{x} f(x), \quad \text{subject to } \quad  g(x)=0.
$$&lt;/p&gt;
&lt;p&gt;我們引進 Lagrangian function
$$
L(x, \lambda) = f(x) + \lambda g(x)
$$
並且知道原問題的解發生在 $\nabla L=0$ 的地方.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; 從微積分我們知道 $\nabla L=0$ 是 $L(x, \lambda)$ 這個函數 critical point發生的地方, 那這個 critical point 究竟是 local max/min 還是 saddle 呢?&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;要回答這問題其實很簡單, 我們看這個二維函數的判別式就知道. 這函數的變數有兩個分別是 $x$ 以及 $\lambda$, 所以判別式是
$$
L_{xx}L_{\lambda\lambda} - L_{x\lambda}^2 = -(g_x)^2 \le 0
$$
所以我們知道原最佳化問題的解其實是這個 Lagragian function 的 saddle point (至少不是 local max/min)!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Constraint optimization problem&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我們事實上可以考慮更一般的問題
$$
\min_{x} f(x), \quad \text{subject to } \quad  g(x) \le 0.
$$
這樣的問題我們可以定義一樣的 Lagrangian function
$$
L(x, \lambda) = f(x) + \lambda g(x).
$$&lt;/p&gt;
&lt;p&gt;我們有以下這個定理:&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&#34;theorem---saddle-point-sufficient-condition&#34;&gt;Theorem - Saddle point (Sufficient condition)&lt;/h2&gt;
&lt;p&gt;Let $P$ be a constraint optimization problem.
If $(x^+, \lambda^+)$ is a saddle point, that is,
$$\forall x\in\mathbb{R}, \forall\lambda\ge 0, \quad L(x^+, \lambda)\le L(x^+, \lambda^+)\le L(x, \lambda^+),$$
then it is a solution of $P$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;這個證明很簡單.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;根據不等式第一個部分
$$\forall\lambda\ge 0, \quad L(x^+, \lambda)\le L(x^+, \lambda^+)$$
帶入 $L$ 我們得到 $\lambda g(x^+) \le \lambda^+ g(x^+)$.&lt;/p&gt;
&lt;p&gt;由於對所有 $\lambda\ge $ 都對, 我們讓 $\lambda\to\infty$ 得到 $g(x^+)\le 0$.
接著讓 $\lambda\to 0$ 我們得到 $0\le \lambda^+ g(x^+)\le 0$, 因此 $\lambda^+ g(x^+)=0$.&lt;/p&gt;
&lt;p&gt;有這件事後我們再看不等式第二部分, $L(x^+, \lambda^+)\le L(x, \lambda^+)$.
代入 $L$ 以及以上結果我們有 $f(x^+)\le f(x) + \lambda^+ g(x)$.&lt;/p&gt;
&lt;p&gt;因此, 若 $g(x)\le 0$, 我們必定有 $f(x^+)\le f(x)$.&lt;/p&gt;
&lt;p&gt;QED.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;更進一步, 我們可以引進這個 Lagrange dual function:
$$
F(\lambda) = \inf_{x} L(x, \lambda)
$$
也就是固定一個 $\lambda$ 我去找 $L$ 這函數的最大下界(有點像最小值不過不一定要碰到). 據此我們可以引進以下的 dual problem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dual optimization problem&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$$
\max_{\lambda} F(\lambda), \quad \lambda \ge 0.
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;舉個例子&#34;&gt;舉個例子&lt;/h4&gt;
&lt;p&gt;我們考慮這個特別的 constraint optimization 問題
$$
\min_{\pmb{x}\in\mathbb{R}^n}f(\pmb{x}), \quad \text{subject to } \quad  A\pmb{x}-\pmb{b}=\pmb{0},
$$
其中 $A$ 是個矩陣而 $\pmb{b}$ 是個向量. 也就是說限制式為 $g(\pmb{x}) = A\pmb{x}-\pmb{b}$.&lt;/p&gt;
&lt;p&gt;把 Lagrangian function 寫下來就是
$$
L(\pmb{x}, \pmb{\lambda}) = f(\pmb{x}) + \pmb{\lambda}^T(A\pmb{x}-\pmb{b}).
$$
對於 dual problem 我們可以構造一個迭代法來解這問題.&lt;/p&gt;
&lt;p&gt;由 Dual optimization problem 我們知道對於 $F$ 這個函數我們要求其最大值. 所以我們試著朝 gradient 方向走來往上走, 意即
$$
\lambda^{k+1} = \lambda_k + \alpha^k\nabla F(\lambda^k),
$$
其中 $\alpha^k$ 是步長. 而且我們知道 $\nabla F(\lambda^k) = A\pmb{\tilde{x}}-\pmb{b},$ 其中 $\pmb{\tilde{x}} = argmin \ L(\pmb{x}, \pmb{\lambda}^k)$. 因此我們有以下這方法:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dual ascent iteration method:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;第一步: 固定一個 $\pmb{\lambda}$ 我們解一個 optimization 問題
$$
\pmb{x}^{k+1} = argmin \ L(x, \pmb{\lambda}^k)
$$
&lt;strong&gt;Remark:&lt;/strong&gt; 這是一個沒有 constraint 的最小值問題, 可以用 gradient descent 或各式方法來解.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;第二步: 接著我們用 gradient ascent 來更新 $\pmb{\lambda}$
$$
\lambda^{k+1} = \lambda^k + \alpha^k(A\pmb{x}^{k+1}-\pmb{b})
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;迭代下去我們可以得到原問題的解!&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;augmented-lagrangian&#34;&gt;Augmented Lagrangian&lt;/h2&gt;
&lt;p&gt;一個很有趣的更進一步推廣是將 Lagrangian 引入一個新的 penalty term:
$$
L_{\rho}(\pmb{x}, \pmb{\lambda}) = f(\pmb{x}) + \pmb{\lambda}^T(A\pmb{x}-\pmb{b}) + \frac{\rho}{2}\|A\pmb{x}-\pmb{b}\|^2_2,
$$
其中 $\rho$ 是個常數.&lt;/p&gt;
&lt;p&gt;我們可以反過來將這個 Lagrangian 所對應的限制最佳化問題寫下來:
$$
\min_{\pmb{x}\in\mathbb{R}^n}f(\pmb{x})+\frac{\rho}{2}\|A\pmb{x}-\pmb{b}\|^2_2, \quad \text{subject to } \quad  A\pmb{x}-\pmb{b}=\pmb{0}.
$$
我們可以輕易發現, 加了這新的一項對於這整個問題的最佳解完全沒有影響! 也就是說 $L_{\rho}$ 所得到的解就是原本 $L$ 的解.&lt;/p&gt;
&lt;p&gt;接著我們一樣用 dual ascent iteration method 來解這問題（給定 $\pmb{x}^{k}$ 以及 $\pmb{\lambda}^{k}$).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Method of multiplier:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;第一步: 我們解一個 optimization 問題
$$
\pmb{x}^{k+1} = argmin \ L_{\rho}(\pmb{x}, \pmb{\lambda}^k)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;第二步: 接著我們用 gradient ascent 來更新 $\pmb{\lambda}$
$$
\pmb{\lambda}^{k+1} = \pmb{\lambda}^k + \rho(A\pmb{x}^{k+1}-\pmb{b})
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; 這裡有個有趣的事, 原本的方法中步長是不知道的需要自己決定, 不過在這裡我們卻直接設定步常為 $\rho$. 接下來我們就是要解釋這部分.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;第一步中, 如果 $\pmb{x}^{k+1}$ 是個解那它要滿足 $\nabla_{\pmb{x}} L_{\rho}=0$, 其中整理一下發現
$$
\nabla_{\pmb{x}} L_{\rho}=\nabla_{\pmb{x}} f(\pmb{x}^{k+1}) + A^T\left(\pmb{\lambda}^k + \rho (A\pmb{x}^{k+1}-\pmb{b})\right)=0.
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所以, 如果第二步中的步長我們設定為 $\rho$, 那上式就可以改寫為
$$
\nabla_{\pmb{x}} f(\pmb{x}^{k+1}) + A^T\pmb{\lambda}^{k+1}=0.
$$
有趣的是, 對原本的 Lagrangian 而言我們有
$$
\nabla_{\pmb{x}} L=\nabla_{\pmb{x}} f(\pmb{x}) + A^T\pmb{\lambda},
$$
所以我們這樣設定步長, 剛好使得我們每次算出的 $\pmb{x}^{k+1}$ 以及 $\pmb{\lambda}^{k+1}$ 滿足
$$
\nabla_{\pmb{x}} L(\pmb{x}^{k+1}, \pmb{\lambda}^{k+1})=0.
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;再把以上兩個方法 summarize 一下&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原本問題是
$$
\min_{\pmb{x}} f(\pmb{x}), \quad \text{subject to } \quad  A\pmb{x}-\pmb{b}=\pmb{0}.
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引進 Lagrangian 後變成我們要解以下方程
$$
\nabla_{\pmb{x}} L =\nabla_{\pmb{x}} f(\pmb{x}) + A^T\pmb{\lambda}=0, \quad \nabla_{\pmb{\lambda}} L=A\pmb{x}-\pmb{b}=0.
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我們使用迭代法來解&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;若用 &lt;strong&gt;dual ascent iteration method&lt;/strong&gt;, 則有
$$
L(\pmb{x}^{k+1}, \pmb{\lambda}^k)=0.
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若用 &lt;strong&gt;method of multiplier&lt;/strong&gt;, 則有
$$
L(\pmb{x}^{k+1}, \pmb{\lambda}^{k+1})=0.
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;對於兩種方法, 原問題的 Constraint 都在 $k\to\infty$ 滿足
$$
\lim_{k\to\infty} A\pmb{x}^k-\pmb{b}=0.
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Lagrange Multiplier - 03</title>
      <link>https://teshenglin.github.io/post/2020_lagrange_multiplier_3/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://teshenglin.github.io/post/2020_lagrange_multiplier_3/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;這裡我們討論一下 Lagrange multiplier.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我們知道, 如果想要解以下這個有限制式的最佳化問題
$$
\min_{x} f(x), \quad \text{subject to } \quad  g(x)=k,
$$
一個方式是引進 Lagrange multiplier, $\lambda$, 然後可以列出以下兩個式子
$$
\partial_x f + \lambda \partial_x g = 0, \quad  g(x)=k.
$$&lt;/p&gt;
&lt;h4 id=&#34;question&#34;&gt;Question:&lt;/h4&gt;
&lt;p&gt;解出聯立方程後我們得到 $x^+$, $\lambda^+$, 帶入原函數得到 $f^+=f(x^+)$.
我們知道 $f^+$ 是最佳值, 而 $x^+$ 是最佳解. 那 $\lambda^+$ 是做什麼用的?
看起來只是為了解出原問題所引進的虛擬變數. 它有什麼作用嗎?&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;先說結論, $\lambda^+ = -\frac{df^+}{dk}$. 也就是告訴我們如果稍微改變限制式中的 $k$ 值, 那原題的最佳值會有怎樣的變化.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;我們先引進 Lagrangian function
$$
L(x, \lambda) = f(x) + \lambda (g(x) - k)
$$
並且知道原問題的解發生在 $\nabla L=0$ 的地方, 意即, $\nabla L(x^+, \lambda^+)=0$.
然後我們有
$$
L^+ = L(x^+, \lambda^+) = f(x^+) + \lambda^+(g(x^+)-k) = f^+.
$$&lt;/p&gt;
&lt;p&gt;在這裡我們要稍微小心一點. 固定一個 $k$ 值, 我們就有一個最佳化問題, 然後就可以解出 $x^+$ 跟 $\lambda^+$.
而當 $k$ 值改變時, $x^+$, $\lambda^+$, 甚至 $f^+$ 以及 $L^+$ 也都會跟著改變, 所以我們想像這四個值都是 $k$ 的函數:
$$
x^+ = x^+(k), \ \lambda^+ = \lambda^+(k), \ f^+ = f^+(k), \ L^+ = L^+(k).
$$
再寫清楚一點就是
$$
L^+(k) = \left.L(x, \lambda,k)\right|_{x=x^+(k), \lambda=\lambda^+(k),k=k}
$$&lt;/p&gt;
&lt;p&gt;其中
$$
L(x, \lambda,k) = f(x) + \lambda (g(x) - k).
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; 讀到這邊也許會覺得有個奇怪的地方, 就是為什麼要把 $L$ 從雙變數變成三變數函數.
原因是當寫成 $L(x, \lambda)$ 時 $k$ 是個常數, 是不能變的. 想要改變 $k$ 值需要把它也當成一個變數比較合理.&lt;/p&gt;
&lt;p&gt;接著我們就可以微分
$$
\frac{d L^+}{dk} = \left.\frac{\partial L}{\partial x}\frac{d x}{dk} + \frac{\partial L}{\partial \lambda}\frac{d \lambda}{dk} + \frac{\partial L}{\partial k}\right|_{x=x^+(k), \lambda=\lambda^+(k),k=k} = -\lambda^+.
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt;
$$
\left.\frac{\partial L}{\partial x}\right|_{x=x^+(k), \lambda=\lambda^+(k),k=k}=
\left.\frac{\partial L}{\partial \lambda}\right|_{x=x^+(k), \lambda=\lambda^+(k),k=k}=0.
$$&lt;/p&gt;
&lt;p&gt;由於 $f^+ =L^+$, 所以我們也可以得到 $\frac{d f^+}{dk} = -\lambda^+$.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;舉個例子&#34;&gt;舉個例子&lt;/h4&gt;
&lt;p&gt;以下單位皆為&lt;code&gt;元&lt;/code&gt; or &lt;code&gt;萬元&lt;/code&gt; or &lt;code&gt;千萬元&lt;/code&gt;, 請自行依喜好帶入!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;假設我如果花費 $x$ 買進某一股票在一定時間後賣出可獲得 $2x$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;假設我如果花費 $y$ 買進某一貴金屬在一定時間後賣出可獲得 $10y-y^2$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;假設我總共可運用的財產只有 $10$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那我們可以列出以下限制最佳化問題&lt;/p&gt;
&lt;p&gt;$$
\max_{x,y} f(x,y)=2x+(10y-y^2), \quad \text{subject to } \quad  x+y=10,
$$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;先引進 Lagrangian funtion
$$
L(x,y,\lambda) = 2x+(10y-y^2)+\lambda(x+y-10)
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;列出方程式 $\nabla L=0$:
$$
\frac{\partial L}{\partial x} = 2 + \lambda =0, \quad
\frac{\partial L}{\partial y} = 10-2y + \lambda =0, \quad
\frac{\partial L}{\partial \lambda} = x+y-10 =0.
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解出得到
$$
x^+ = 6, \quad y^+=4, \quad \lambda^+=-2.
$$
也就是我們若以 $6$ 單位買進股票, $4$ 單位買進貴金屬, 一定時間賣出後可獲利 $f^+ = 36$ 單位.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所以 $\lambda^+=-2$ 告訴我們 $\frac{d f^+}{dk}=-\lambda^+=2$, 意思就是如果我們增加一點 $k$ 值, 那獲利會是所增加數目的&lt;strong&gt;兩倍&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;將原題改成我目前可運用的財產有 $11$, 那會發現最佳解是 $x^+=7$, $y^+=4$, $f^+=38$, 獲利真的增加 $2$ 單位了!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;這例子比較特殊 $\lambda^+$ 衡等於 $2$, 所以才會那麼巧資金增加一單位獲利就增加兩單位. 一般而言這應該只是 linear appxoimation, 只有 $k$ 增加一點點時才會大約兩倍. 增加太多就不知道了.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h4 id=&#34;references&#34;&gt;References:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://youtu.be/m-G3K2GPmEQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Meaning of the Lagrange multiplier&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;https://youtu.be/b9B2FZ5cqbM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Proof for the meaning of Lagrange multipliers&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>以內插多項式來做數值積分</title>
      <link>https://teshenglin.github.io/post/2020_numerical_integration_2/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://teshenglin.github.io/post/2020_numerical_integration_2/</guid>
      <description>&lt;p&gt;前情提要: 
&lt;a href=&#34;https://teshenglin.github.io/post/2019_numerical_integration&#34;&gt;數值積分初探&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;連續函數可以用多項式來逼近它, 因此直覺來講, 既然我們已經找到一個離給定函數&amp;quot;很近&amp;quot;的多項式了, 何不就以這個多項式的積分值來當成原函數積分值的一個逼近呢.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;goal-任意給定一可積分函數-fx-xin-1-1-我們想要算-int1_-1-fx-dx&#34;&gt;Goal: 任意給定一可積分函數 $f(x)$, $x\in[-1, 1]$, 我們想要算 $\int^1_{-1} f(x) dx$.&lt;/h4&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;我們先講內插多項式&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;給定任意 $n+1$ 個不重複的點在 $[-1, 1]$ 區間, 我們把他們記為 $x_0, x_1, \cdots, x_n.$
接著我們計算函數 $f(x)$ 在這些點上的值, 記為 $f_i = f(x_i)$, 這樣我們就有平面上的 $n+1$ 個點座標 $(x_i, f_i)$.&lt;/p&gt;
&lt;p&gt;有這些點我們就一定能找到一個 $n$ 次多項式 $p_n(x)$ 使得說這個多項式會通過這些所有的點, 也就是 $p_n(x_i) = f_i$. 這就叫做內插多項式.&lt;/p&gt;
&lt;p&gt;內插多項式一個很簡潔的表示法是把它寫成 Lagrange polynomial 的樣子. 我們先引進 Lagrange basis function
$$
\ell_i(x) = \prod^n_{k=0, k\ne i} \frac{x-x_k}{x_i-x_k}.
$$
很明顯可以看出這是一個 $n$ 次多項式, 而且有很特殊的性質, 也就是 $\ell_i(x_j)=\delta_{ij}$.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$\delta_{ij}$ 是所謂的 Kronecker delta function, 如果 $i=j$ 則 $\delta_{ij}=1$, 反之如果 $i\ne j$ 則 $\delta_{ij}=0$. 舉例來說, $\delta_{11}=1$, 而 $\delta_{12}=0$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;因此我們可以將內插多項式 $p_n(x)$ 改寫成
$$
p_n(x) = \sum^n_{i=0} f_i \ell_i(x).
$$
這就是內插多項式的 Lagrange 表示法.&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;接著我們就可以來做積分了!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我們直接以內插多項式來逼近函數並做積分,
$$
\int^1_{-1} f(x)dx \approx \int^1_{-1} p_n(x)dx = \int^1_{-1} \sum^n_{i=0} f_i \ell_i(x)dx = \sum^n_{i=0} f_i \left(\int^1_{-1} \ell_i(x)dx\right).
$$
理論上, 如果插值點 $x_i$ 是一開始就給定並且固定的, 那我們就可以把 Lagrange basis function $\ell_i(x)$ 算出來, 並且把他的積分也算出來. 我們把積分出來的值記為 $w_i$, 也就是
$$
w_i = \int^1_{-1} \ell_i(x)dx.
$$
如此我們就可以把積分改寫成
$$
\int^1_{-1} f(x)dx \approx \sum^n_{i=0} w_i f_i.
$$
這就是以內插多項式來做積分.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; 如果 $f(x)$ 本身就是個 $n$ 次或以下的多項式, 那我們做出來的內插多項式就不是 approximation 而是等號了. 那這樣我們做出來的積分事實上應該就是等號! 也就是說
$$
\int^1_{-1} p(x)dx = \sum^n_{i=0} w_i f_i,
$$
where $p(x)$ is a polynomial with degree less than or equals to $n$.&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;舉個簡單的例子來試試&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假設我們只想要用兩個端點來估算積分, 那我們有 $x_0=-1, x_1=1$. 因此得到 Lagrange basis polynomials
$$
\ell_0(x) = \frac{x+1}{2}, \quad \ell_1(x)=\frac{x-1}{-2}.
$$
接著可以算出
$$
w_0 = \int^1_{-1} \ell_0(x)dx = 1, \quad w_1=\int^1_{-1}\ell_1(x)dx=1.
$$
也就是說
$$
\int^1_{-1} f(x)dx \approx f(-1) + f(1),
$$
得到所謂的梯形法!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;延伸閱讀: 
&lt;a href=&#34;https://teshenglin.github.io/post/2020_numerical_integration_3&#34;&gt;高斯積分&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>高斯積分</title>
      <link>https://teshenglin.github.io/post/2020_numerical_integration_3/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://teshenglin.github.io/post/2020_numerical_integration_3/</guid>
      <description>&lt;p&gt;前情提要: 
&lt;a href=&#34;https://teshenglin.github.io/post/2019_numerical_integration&#34;&gt;數值積分初探&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前情提要: 
&lt;a href=&#34;https://teshenglin.github.io/post/2020_numerical_integration_2&#34;&gt;以內插多項式來做數值積分&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;我們想要找到一些插值點使得以內插多項式來做數值積分會最準. 這就是高斯積分.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;goal-任意給定一可積分函數-fx-xin-1-1-我們想要算-int1_-1-fx-dx&#34;&gt;Goal: 任意給定一可積分函數 $f(x)$, $x\in[-1, 1]$, 我們想要算 $\int^1_{-1} f(x) dx$.&lt;/h4&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;複習一下內插多項式的積分&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;給定任意 $n+1$ 個不重複的點在 $[-1, 1]$ 區間, 記為 $x_0, x_1, \cdots, x_n.$ 我們可以逼近函數 $f(x)$ 的積分
$$
\int^1_{-1} f(x)dx \approx \sum^n_{i=0} w_i f_i,
$$
其中 $f_i = f(x_i)$, 並且
$$
w_i = \int^1_{-1} \ell_i(x)dx = \int^1_{-1} \left(\prod^n_{k=0, k\ne i} \frac{x-x_k}{x_i-x_k}\right) dx.
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一個重要的 remark: 如果 $p(x)$ 是個 $n$ 次或以下的多項式, 那這個積分是等號!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;也就是說
$$
\int^1_{-1} p(x)dx = \sum^n_{i=0} w_i f_i,
$$
where $p(x)$ is a polynomial with degree less than or equals to $n$.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;idea&#34;&gt;Idea:&lt;/h4&gt;
&lt;p&gt;高斯積分的想法就是, 我想要找到特別的點 $x_i$ 以及特別的權重 $w_i$ 使得我能算準的多項式次數最高.&lt;/p&gt;
&lt;p&gt;如果我們回想一下內插多項式, 給定點然後求 $n+1$ 個權重, 也就是有 $n+1$ 個未知數, 那顯然它所能滿足的方程式就是 $n+1$ 個. 如果要把多項式算準的話從常數($0$次)到 $n$次共可以列出剛好 $n+1$個方程式. 所以最多能把 $n$ 次多項式算準.&lt;/p&gt;
&lt;p&gt;現在假設點($x_i$)跟權重($w_i$)都是待決定的, 那我就有 $2(n+1)$ 個未知數, 能夠把多項式從常數($0$次)到 $2n+1$次都算準. 所以理論上, $n+1$ 個點的高斯積分可以將 $2n+1$次的多項式算準, 完全沒有誤差.&lt;/p&gt;
&lt;p&gt;那如果這這樣的想法直接列式的話就會得到以下 $2n+1$ 個方程式
$$
\int^1_{-1} x^m dx=\frac{1 - (-1)^{m+1}}{m+1} =  \sum^n_{i=0} w_i x^m_i, \quad 0\le m\le 2n+1.
$$
然後解以上的非線性聯立方程式就可以得到所有的點 $x_i$ 及權重 $w_i$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;看起來有點困難&lt;/strong&gt;, 不過好消息是其實不難解.&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;我們需要引進正交多項式 (orthogonal polynomials)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在線性代數裡我們知道兩個向量如果正交則其內積等於零. 函數空間裡我們也可以做一樣的定義, 我們定義兩個函數的內積
$$
(f, g) = \int^1_{-1} f(x)g(x) dx.
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&#34;definition&#34;&gt;Definition&lt;/h2&gt;
&lt;p&gt;$f(x)$ and $g(x)$ are orthogonal if $(f,g)=0$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我們知道 $n$ 次多項式有一組最基本的基底 ${1, x, x^2, \cdots, x^n}$, 將這組基底以 Gram-Schimidt 做正交化就可以得到一組正交基底. 這組正交基底就是所謂的 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Legendre_polynomials&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Legendre polynomials&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;我們將 Legendre polynomials 這組正交基底記為 $P_i(x)$, 其前三個如下:
$$
P_0(x) = 1, \quad P_1(x) = x, \quad P_2(x)=\frac{1}{2}(3x^2-1).
$$&lt;/p&gt;
&lt;p&gt;Legendre polynomials 有以下兩個性質:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$P_i(x)$ 是一個 $i$次多項式&lt;/li&gt;
&lt;li&gt;$(P_i(x), P_j(x)) = \delta_{ij}$
&lt;ul&gt;
&lt;li&gt;對任何多項式 $Q(x)$ 如果其次數小於 $i$, 則有 $(P_i(x), Q(x))=0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h4 id=&#34;高斯積分的點與權重&#34;&gt;高斯積分的點與權重:&lt;/h4&gt;
&lt;p&gt;任意給定一個 $2n+1$ 次多項式 $p(x)$, 我們可以透過多項式的除法把它分解成以下這種樣子
$$
p(x) = P_{n+1}(x)Q(x) + R(x),
$$
其中 $Q(x)$ 以及 $R(x)$ 都是至多 $n$ 次的多項式. 透過這樣的分解我們發現
$$
\int^1_{-1} p(x)dx = \int^1_{-1} P_{n+1}(x)Q(x) + R(x)dx = \int^1_{-1} R(x)dx,
$$
其中 $P_{n+1}$ 與 $Q$ 相丞後的積分等於零是用到上面正交多項式的性質.&lt;/p&gt;
&lt;p&gt;以上這積分如果以數值積分來表示的話就是
$$
\int^1_{-1} p(x)dx \approx \sum^n_{i=0} w_i p(x_i) = \sum^n_{i=0} w_i \left(P_{n+1}(x_i)Q(x_i) + R(x_i)\right).
$$
我們希望數值積分也會有 &amp;ldquo;$P_{n+1}$ 與 $Q$ 相乘的積分等於零&amp;rdquo; 這件事. 那一個最簡單的取法就是我們取 $x_i$ 是 $P_{n+1}(x)$ 這個 $n+1$ 次多項式所有的根. 由於 $P_{n+1}$ 剛好有 $n+1$ 個不重複的根, 這樣我們就有 $x_i$ 這些點了, 而且 $P_{n+1}(x_i)=0$ 表示
$$
\sum^n_{i=0} w_i P_{n+1}(x_i)Q(x_i)=0,
$$
所以
$$
\int^1_{-1} p(x)dx \approx \sum^n_{i=0} w_i R(x_i),
$$
也就是說我們只需要把 $R(x)$ 這個 $n$ 次多項式算準就好. 那我們就可以用內插多項式算權重的方法把權重都寫下來
$$
w_i = \int^1_{-1} \left(\prod^n_{k=0, k\ne i} \frac{x-x_k}{x_i-x_k}\right) dx.
$$&lt;/p&gt;
&lt;p&gt;如此, 我們就把&lt;code&gt;點&lt;/code&gt;跟&lt;code&gt;權重&lt;/code&gt;都求出來了.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary:&lt;/h3&gt;
&lt;p&gt;最後總結一下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$n+1$ 個點的高斯積分可以將 $2n+1$ 次多項式算準無誤差&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;高斯點是正交多項式 $P_{n+1}(x)$ 的 $n+1$ 個根&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;求出高斯點後我們以內插多項式的做法來求出權重&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;舉個簡單的例子來試試&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假設我們只想要用兩個點來估算積分, 那 Legendre polynomial 的 $P_2(x)=\frac{1}{2}(3x^2-1)$.&lt;/p&gt;
&lt;p&gt;由此可算出兩個高斯點, 也就是 $P_2$ 的兩個根是
$$
x_0 = -\frac{1}{\sqrt{3}}, \quad x_1 = \frac{1}{\sqrt{3}}.
$$
接著權重也可以簡單的算出來, 我們得到.
$$
w_0 = w_1 = 1.
$$
因此, 兩個點的高斯積分公式是
$$
\int^1_{-1} f(x)dx = f\left(-\frac{1}{\sqrt{3}}\right) + f\left(\frac{1}{\sqrt{3}}\right),
$$
可以將 3次(含)以下的多項式算準無誤差.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;再延伸一下&#34;&gt;再延伸一下&lt;/h4&gt;
&lt;p&gt;對於更廣義有權重的積分
$$
\int^1_{-1} w(x)f(x)dx,
$$
我們只要找出相對應的正交多項式, 我們一樣可以求出其高斯積分點以及權重.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;舉例來說, $w(x)=\frac{1}{1+x^2}$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其相對應的內積以及積分為
$$
(f,g) = \int^1_{-1} \frac{1}{1+x^2}f(x)g(x)dx, \quad \int^1_{-1} \frac{1}{1+x^2}f(x)dx.
$$
其正交多項式為 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Chebyshev_polynomials&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chebyshev polynomials&lt;/a&gt;, $T_i(x)$, 前三項為:
$$
T_0(x) = 1, \quad T_1(x) =x, \quad T_2(x) = 2x^2-1.
$$
比較特別的是其高斯點, 稱為 Gauss-Chebyshev points, 可以直接求出來:
$$
x_i = \cos\left(\frac{(i+\frac{1}{2})\pi}{n+1}\right), \quad 0\le i\le n.
$$
而且權重也可以直接求出來:
$$
w_i = \frac{\pi}{n+1}.
$$&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>數值積分初探</title>
      <link>https://teshenglin.github.io/post/2019_numerical_integration/</link>
      <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://teshenglin.github.io/post/2019_numerical_integration/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;在微積分課程裡我們有學到積分的&#39;中點法&amp;rsquo;, &amp;lsquo;梯形法&#39;以及&#39;辛普森法&amp;rsquo;. 這裡我們簡介一些基本概念並且引進高斯積分法.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;goal-任意給定一可積分函數-fx-xin-1-1-我們想要算-int1_-1-fx-dx&#34;&gt;Goal: 任意給定一可積分函數 $f(x)$, $x\in[-1, 1]$, 我們想要算 $\int^1_{-1} f(x) dx$.&lt;/h4&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; 對任一個積分式 $\int^b_{a} g(x),dx$ 我們皆可用變數變換來將此積分轉到 $[-1, 1]$ 這個區間. 所以我們只需考慮 $[-1, 1]$ 即可.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;首先我們討論一下哪種方法比較準. 一個最簡單的判斷方法是看積分法能不能將多項式算準.&lt;/p&gt;
&lt;p&gt;我們考慮三種積分法:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Midpoint rule: $\int^1_{-1}f(x),dx\approx 2f(0)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Trapezoidal rule: $\int^1_{-1}f(x),dx\approx f(-1)+f(1)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simpson&amp;rsquo;s rule: $\int^1_{-1}f(x),dx\approx \frac{1}{3}(f(-1)+4f(0)+f(1))$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;我們先檢驗常數函數: $\int^1_{-1} 1,dx=2$. 很快我們就可以發現以上三種方法都可以得出完全正確的答案.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;接著我們檢驗一次函數: $\int^1_{-1} x,dx=0$. 一樣, 三種方法都得出正確答案.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;二次函數: $\int^1_{-1} x^2,dx=\frac{2}{3}$. 對於二次函數我們發現, 中點法以及梯形法都無法算出正確答案, 只有辛普森法能成功.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;三次函數: $\int^1_{-1} x^3,dx=0$. 對於三次函數我們只檢驗辛普森法, 發現三次函數辛普森法也能算準.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;四次函數: $\int^1_{-1} x^4,dx=\frac{2}{5}$. 對於四次函數, 辛普森法就算錯了.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;小結論&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;中點跟梯形法準確率相同, 能準確的算出任意一次多項式的積分值.&lt;/li&gt;
&lt;li&gt;辛普森法比中點及梯形法更準確, 並且它能準確的算出任意三次多項式的積分值.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;接著我們稍微推廣一下, 並且介紹所謂的&#39;高斯積分&amp;rsquo;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; 假設我們現在想要用函數在 $x=0$ 這個點的值來估算積分, 那係數要取多少會最好?&lt;/p&gt;
&lt;p&gt;也就是說我們假設
$$\int^1_{-1}f(x),dx\approx A_0f(0),$$
其中 $A_0$ 是個常數. 那 $A_0$ 要選哪個數字, 這個積分公式才會算的最準?&lt;/p&gt;
&lt;p&gt;依照我們之前的想法, 要讓積分式準就是要讓他把多項式算準. 所以我們希望他至少能把常數函數算準. 這樣的話很容易就看出 $A_0=2$, 也就是&#39;中點法&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; 假設我們現在想要用函數在 $x=-1$ 以及 $x=1$ 這兩個點的值來估算積分, 那係數要取多少會最好?&lt;/p&gt;
&lt;p&gt;也就是說我們假設
$$\int^1_{-1}f(x),dx\approx \alpha f(-1)+\beta f(1),$$
其中 $\alpha, \beta$ 是常數.&lt;/p&gt;
&lt;p&gt;我們有兩個未知數, 所以我們希望他至少能把常數及一次函數算準. 這樣的話我們可以列出方程式:
$$
\alpha + \beta = 2, \quad -\alpha + \beta = 0.
$$
解方程式我們得到 $\alpha=\beta=1$, 也就是梯形法.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; 假設我們現在只想用兩個點的值來估算積分, 那怎樣做會最好?&lt;/p&gt;
&lt;p&gt;也就是說我們假設
$$\int^1_{-1}f(x),dx\approx A_0 f(x_0)+A_1 f(x_1),$$
其中 $A_0, A_1, x_0, x_1$ 都待決定.&lt;/p&gt;
&lt;p&gt;我們有四個未知數, 所以理想狀況下應該能從常數到三次多項式都能算準, 依此可以列出四個方程式:
$$
\begin{aligned}
A_0 + A_1 &amp;amp;= 2 \\\&lt;br&gt;
A_0x_0 + A_1x_1 &amp;amp;= 0 \\\&lt;br&gt;
A_0x^2_0 + A_1x^2_1 &amp;amp;= \frac{2}{3} \\\&lt;br&gt;
A_0x^3_0 + A_1x^3_1 &amp;amp;= 0.
\end{aligned}
$$
解方程式我們得到 $A_0=A_1=1$, $x_0=-\frac{1}{\sqrt{3}}$, $x_1=\frac{1}{\sqrt{3}}$. 也就是說&lt;/p&gt;
&lt;p&gt;$$
\int^1_{-1} f(x),dx \approx f\left(-\frac{1}{\sqrt{3}}\right)+ f\left(\frac{1}{\sqrt{3}}\right).
$$
這就是所謂的兩點高斯積分公式 (two-point Gaussian quadrature formula).&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;最後我們看一下以數值積分來估算的例子.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我們想計算 $\int^1_{-1} e^x,dx$, 當然我們知道答案是 $e^1-e^{-1}$, 不過我們想要知道若以上列幾種方法估算會有多準確.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; 一般來說我們會先將所要積分的範圍分成 $n$ 等分, 接著在每一等分上使用上列積分法. 這就是微積分課本中所介紹的合成積分法 (composite integral rules). 實作上的細節我們就不在這裡討論.&lt;/p&gt;
&lt;p&gt;我們將 $[-1, 1]$ 區間均勻分成 $n$ 等分, 再用三種不同積分法來估算積分值. 下表列出不同積分法在不同區間數所得之值與實際值之間的絕對誤差.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;n\Method&lt;/th&gt;
&lt;th&gt;Midpoint&lt;/th&gt;
&lt;th&gt;Trapezoidal&lt;/th&gt;
&lt;th&gt;Simpson&amp;rsquo;s&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;3.91e-3&lt;/td&gt;
&lt;td&gt;7.83e-3&lt;/td&gt;
&lt;td&gt;2.08e-5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;3.92e-5&lt;/td&gt;
&lt;td&gt;7.83e-5&lt;/td&gt;
&lt;td&gt;2.09e-9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;td&gt;3.92e-7&lt;/td&gt;
&lt;td&gt;7.83e-7&lt;/td&gt;
&lt;td&gt;2.10e-13&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;我們可以看到, 中點以及梯形法誤差皆是以 $O(n^{-2})$ 來下降, 也就是點數變十倍時誤差會降一百倍, 而辛普森法則是 $O(n^{-4})$.&lt;/p&gt;
&lt;p&gt;接著我們試試看用高斯積分來做, 這裡我們就不分小區間, 直接做整個 $[-1, 1]$ 區間. 多個點的高斯積分的公式可在 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Gaussian_quadrature&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wiki&lt;/a&gt; 找到. 我們將 $m$-point 高斯積分所得之值與實際值之間的絕對誤差列於下表&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;m\Method&lt;/th&gt;
&lt;th&gt;Gaussian quadrature rule&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;7.71e-3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;6.55e-5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2.95e-7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;8.25e-10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;1.56e-12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2.66e-15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;4.44e-16&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;可以看到我們用 8 個點就可以將這個積分準確估計到誤差接近機器的捨入誤差 (rounding error).&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;延伸閱讀: 
&lt;a href=&#34;https://teshenglin.github.io/post/2020_numerical_integration_2&#34;&gt;以內差多項式來做數值積分&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;延伸閱讀: 
&lt;a href=&#34;https://teshenglin.github.io/post/2020_numerical_integration_3&#34;&gt;高斯積分&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Fixed point iteration</title>
      <link>https://teshenglin.github.io/post/2019_fixed_point/</link>
      <pubDate>Mon, 04 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://teshenglin.github.io/post/2019_fixed_point/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;這裡我們介紹固定點迭代法 (Fixed point iteration)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先我們介紹什麼是固定點 (Fixed point)&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&#34;definition-fixed-point&#34;&gt;Definition: Fixed point&lt;/h2&gt;
&lt;p&gt;A fixed point of a function $f(x)$ is a number $c$ in its domain such that $f(c)=c$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以簡單來說, 把固定點這個數字丟進函數後會得到同樣的一個數字. 所以稱之為固定點.&lt;/p&gt;
&lt;p&gt;那固定點重要性其一是在數值計算上有一種迭代方式叫做固定點迭代(Fixed point iteration). 假設我們想要求某個函數的固定點, 也就是滿足 $c=f(c )$ 的這些 $c$, 那我們可以定義一個迭代式
$$
x_{n+1} = f(x_n).
$$&lt;/p&gt;
&lt;p&gt;如果夠幸運的, $\{x_{n}\}$ 這串數字收斂了, 那把它收斂到的數字稱為 $\bar{c}$ 我們就有 $\bar{c}=f(\bar{c})$, 也就是固定點.&lt;/p&gt;
&lt;p&gt;舉個例子來說, 假設我們想要解 $x=\cos(x)$ 這個方程式, 那我們可以定義一個固定點迭代為
$$
x_{n+1} = \cos(x_n).
$$&lt;/p&gt;
&lt;p&gt;這樣的話如果數列收斂, $\{x_{n}\}\to \bar{x}$, 那我們就有 $\bar{x}=\cos(\bar{x})$, 那就解出來了!!&lt;/p&gt;
&lt;p&gt;不過這裡有兩個問題.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;為什麼這個數列會收斂?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;原方程式的固定點迭代其實有無窮多種改寫方式, 例如也可寫為 $x_{n+1} = \cos^{-1}(x_n)$. 如果收斂的話一樣會是原方程式的解. 那, 哪種改寫方式最好呢?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我們有以下這個定理&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&#34;theorem&#34;&gt;Theorem&lt;/h2&gt;
&lt;p&gt;If $f:[a, b]\to [a,b]$ is a differentiable function such that
$$ |f&amp;rsquo;(x)|\leq \alpha&amp;lt;1, \quad \forall x\in[a, b],$$
then $f$ has exactly one fixed point $c$ and the fixed point iteration converges to $c$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;這個證明很簡單.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h3 id=&#34;proof&#34;&gt;Proof&lt;/h3&gt;
&lt;h3 id=&#34;sketch-not-complete-please-full-in-the-details-by-yourself&#34;&gt;(Sketch, not complete, please full-in the details by yourself)&lt;/h3&gt;
&lt;h4 id=&#34;existence&#34;&gt;existence&lt;/h4&gt;
&lt;p&gt;Since the domain and the range of $f$ are both $[a, b]$, by Intermediate Value Theorem, there exists $c$ such that $c=f(c ).$&lt;/p&gt;
&lt;h4 id=&#34;uniqueness&#34;&gt;uniqueness&lt;/h4&gt;
&lt;p&gt;If there exits another fixed point $\bar{c}$, $\bar{c}\ne c$, such that $\bar{c}=f(\bar{c} )$, then according to Mean Value Theorem(MVT), there exits $z$ between $c$ and $\bar{c}$ such that $$f&amp;rsquo;(z) = \frac{f(c ) - f(\bar{c})}{c-\bar{c}}=\frac{c - \bar{c}}{c-\bar{c}} = 1,$$ which violate the assumption that $|f&#39;|\leq \alpha&amp;lt;1$. So the fixed point is unique.&lt;/p&gt;
&lt;h4 id=&#34;convergence-of-fixed-point-iteration&#34;&gt;convergence of fixed point iteration&lt;/h4&gt;
&lt;p&gt;Based on MVT we have
$$|x_{n+1} - c| = |f(x_n) - f(c )| = |f&amp;rsquo;(c_i)(x_n-c)|\leq\alpha |x_n-c|\leq\alpha^n|x_1-c|\to 0.$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以如果在函數固定點 $c$ 的微分小於 $1$, 那就存在一個包含 $c$ 的小區間使得函數的微分都在這區間內小於 $1$, 那根據這定理固定點迭代就會收斂.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;固定點迭代是求根問題(root finding problems)中很重要的一種迭代方式. 舉個例子來說, 假設我們想要找 $g(x)$ 這個函數的根, 那我們可以定義
$$
f(x) = x + g(x).
$$
這樣的話 $f$ 的固定點就會是 $g$ 的根了. 不過這種最簡單的改寫方式完全不保證會收斂.&lt;/p&gt;
&lt;p&gt;那要如何改寫才會比較好呢? 其中一個最有名的就是牛頓法 (Newton&amp;rsquo;s method):&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&#34;newtons-iteration&#34;&gt;Newton&amp;rsquo;s iteration&lt;/h2&gt;
&lt;p&gt;$$x_{n+1} = x_n - \frac{g(x_n)}{g&amp;rsquo;(x_n)}.$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我們可以定義 $f(x) = x - \frac{g(x)}{g&amp;rsquo;(x)}$, 這樣上面這個式子就是個固定點迭代. 接著我們可以發現, 如果 $c$ 是 $g$ 函數的根, 也就是 $g(c )=0$, 那 $f&amp;rsquo;(c ) = 0$. 所以根據上面的定理就存在某個包含 $c$ 的小區間使得迭代會收斂.&lt;/p&gt;
&lt;p&gt;更進一步我們可以利用泰勒展開式(Taylor&amp;rsquo;s series expansion) 來證明牛頓法事實上有二次收斂,
$$
|x_{n+1} - c| \approx \beta |x_n-c|^2.
$$
這個證明我們這邊就先略過不寫. 不過接著我們來看一下牛頓法究竟有多快.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;依之前的例子我們想要解 $x=\cos(x)$, $x\in[0, \pi]$. 最簡單的固定點迭代為
$$
x_{n+1} = \cos(x_n),
$$
也就是求 $g(x) = \cos(x)-x$ 的根. 我們以 $x_0=1$ 當初始值, 發現需要 $80$ 個迭代才能使誤差在 $10^{-14}$ 之下.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    x_new= 0.5403023058681398		error= 0.31725090997825367
    x_new= 0.8575532158463934		error= 0.2032634253486143
    x_new= 0.6542897904977791		error= 0.13919056824478648
    x_new= 0.7934803587425656		error= 0.0921115851198091
    x_new= 0.7013687736227565		error= 0.06259090927789768
    ⋮
    x_new= 0.7390851332151851		error= 4.0967229608668276e-14
    x_new= 0.7390851332151441		error= 2.7644553313166398e-14
    x_new= 0.7390851332151718		error= 1.865174681370263e-14
    x_new= 0.7390851332151531		error= 1.2545520178264269e-14
    x_new= 0.7390851332151657		error= 8.43769498715119e-15
    Total number of iterations=80
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;若是使用牛頓法迭代則迭代式為
$$
x_{n+1} = x_n + \frac{cos(x_n)- x_n}{\sin(x_n)+1}.
$$
一樣以 $x_0=1$ 當初始值, 發現只需要 $4$ 個迭代就能使誤差在 $10^{-14}$ 之下. 比上個例子快上許多.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    x_new= 0.7503638678402439		error= 0.018923073822117442
    x_new= 0.7391128909113617		error= 4.6455898990771516e-5
    x_new= 0.739085133385284		error= 2.847205804457076e-10
    x_new= 0.7390851332151607		error= 0.0
    Total number of iterations=4
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary:&lt;/h3&gt;
&lt;p&gt;最後總結一下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;固定點迭代要收斂, 至少在固定點的微分值必須比 $1$ 小.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;要取迭代函數, 如果知道如何對函數微分, 以牛頓法 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Newton%27s_method&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Newton&amp;rsquo;s method&lt;/a&gt; 來取通常會有不錯的效果.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若無法得知微分函數, 可以用數值微分來逼近真實微分, 這樣會得到割線法 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Secant_method&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;secant method&lt;/a&gt;, 收斂速度比牛頓法慢一點點.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;固定點定理保證在區間裡任意取點當初使迭代都會收斂, 不過要滿足定理的條件很強, 實務上不容易做到.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;例如牛頓法, 我們能證明一定存在某個區間滿足固定點定理, 不過實際上這個區間有多大並不知道. 因此一般在討論牛頓法時都會要求初始值要離實際要求的固定點&amp;quot;夠近&amp;rdquo;. 至於&amp;quot;夠近&amp;quot;什麼意思就只能用嘗試的.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;由於牛頓法不保證收斂, 因此實務上要求根時會與一些保證收斂的方法, 如二分逼進法 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Bisection_method&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(bisection method)&lt;/a&gt; 來合作. 如 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Brent%27s_method&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brent-Dekker method&lt;/a&gt;. 這樣既能保證收斂, 又兼有收斂快速的優點.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>用電腦算微分</title>
      <link>https://teshenglin.github.io/post/2019_derivate_evaluate/</link>
      <pubDate>Sun, 27 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://teshenglin.github.io/post/2019_derivate_evaluate/</guid>
      <description>&lt;p&gt;前情提要: 
&lt;a href=&#34;https://teshenglin.github.io/post/2019_limit_evaluate&#34;&gt;用電腦算極限&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;這裡我們要講的是用數值計算來算函數的微分值.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;已知一個函數 $f(x)$ 在某個點 $a$ 的微分值定義是
$$
f&amp;rsquo;(a) = \lim_{h\to 0} \frac{f(a+h)-f(a)}{h}.
$$&lt;/p&gt;
&lt;p&gt;我們用一個簡單的例子試試看. 假設我們想求 $f(x)=x^2$ 在 $x=\pi$ 的微分. 根據定義我們有&lt;/p&gt;
&lt;p&gt;$$
f&amp;rsquo;(\pi) = \lim_{h\to 0} \frac{(\pi+h)^2-\pi^2}{h}.
$$&lt;/p&gt;
&lt;p&gt;接著我們將 $h$ 取靠近 $0$ 的 $11$ 的點並帶入上列這個式子試著來算其極限值. &lt;code&gt;Julia&lt;/code&gt; 程式如下&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-julia&#34; data-lang=&#34;julia&#34;&gt;h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01&lt;/span&gt;, length&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;); h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; h[&lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;];
fp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ((pi&lt;span style=&#34;color:#f92672&#34;&gt;.+&lt;/span&gt;h)&lt;span style=&#34;color:#f92672&#34;&gt;.^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;.-&lt;/span&gt; pi&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;./&lt;/span&gt;h;
hcat(h, fp, fp&lt;span style=&#34;color:#f92672&#34;&gt;.-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;pi)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;結果如下:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;$h$&lt;/th&gt;
&lt;th&gt;$f&#39;$&lt;/th&gt;
&lt;th&gt;$f&amp;rsquo;-2\pi$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.01&lt;/td&gt;
&lt;td&gt;6.29319&lt;/td&gt;
&lt;td&gt;0.01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.009&lt;/td&gt;
&lt;td&gt;6.29219&lt;/td&gt;
&lt;td&gt;0.009&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.008&lt;/td&gt;
&lt;td&gt;6.29119&lt;/td&gt;
&lt;td&gt;0.008&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.007&lt;/td&gt;
&lt;td&gt;6.29019&lt;/td&gt;
&lt;td&gt;0.007&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.006&lt;/td&gt;
&lt;td&gt;6.28919&lt;/td&gt;
&lt;td&gt;0.006&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.005&lt;/td&gt;
&lt;td&gt;6.28819&lt;/td&gt;
&lt;td&gt;0.005&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.004&lt;/td&gt;
&lt;td&gt;6.28719&lt;/td&gt;
&lt;td&gt;0.004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.003&lt;/td&gt;
&lt;td&gt;6.28619&lt;/td&gt;
&lt;td&gt;0.003&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.002&lt;/td&gt;
&lt;td&gt;6.28519&lt;/td&gt;
&lt;td&gt;0.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.001&lt;/td&gt;
&lt;td&gt;6.28419&lt;/td&gt;
&lt;td&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;上列數字最左邊是 $h$ 值, 中間為估計的微分值. 我們發現的確這個數字會越來越接近真實的解, 也就是 $2\pi$, 約等於 $6.283185307179586$. 最右邊為這個估算值與真實值 $2\pi$ 之間的差. 的確, 當 $h$ 越接近零, 這個估計出來的微分值離 $2\pi$ 的距離越來越小.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; 用數值計算微分能有多精確? 這個誤差能不能一直遞減下去?&lt;/p&gt;
&lt;p&gt;接著我們取更多靠近 $0$ 的點來計算微分的極限值, 我們列出其與真實值 $2\pi$ 之間的差, 並且把它畫出來.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-julia&#34; data-lang=&#34;julia&#34;&gt;h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, length&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;); h &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10.0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.^&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;h[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;]);
fp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ((pi&lt;span style=&#34;color:#f92672&#34;&gt;.+&lt;/span&gt;h)&lt;span style=&#34;color:#f92672&#34;&gt;.^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;.-&lt;/span&gt; pi&lt;span style=&#34;color:#f92672&#34;&gt;^&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;./&lt;/span&gt;h;
hcat(h, fp, abs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;(fp&lt;span style=&#34;color:#f92672&#34;&gt;.-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;pi))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;結果如下:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;$h$&lt;/th&gt;
&lt;th&gt;$f&#39;$&lt;/th&gt;
&lt;th&gt;$abs(f&amp;rsquo;-2\pi)$&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;6.38319&lt;/td&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.01&lt;/td&gt;
&lt;td&gt;6.29319&lt;/td&gt;
&lt;td&gt;0.01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.001&lt;/td&gt;
&lt;td&gt;6.28419&lt;/td&gt;
&lt;td&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0.0001&lt;/td&gt;
&lt;td&gt;6.28329&lt;/td&gt;
&lt;td&gt;0.0001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-5&lt;/td&gt;
&lt;td&gt;6.2832&lt;/td&gt;
&lt;td&gt;9.99998e-6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-6&lt;/td&gt;
&lt;td&gt;6.28319&lt;/td&gt;
&lt;td&gt;1.00006e-6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-7&lt;/td&gt;
&lt;td&gt;6.28319&lt;/td&gt;
&lt;td&gt;9.5898e-8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-8&lt;/td&gt;
&lt;td&gt;6.28319&lt;/td&gt;
&lt;td&gt;4.26073e-8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-9&lt;/td&gt;
&lt;td&gt;6.28319&lt;/td&gt;
&lt;td&gt;2.20243e-7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-10&lt;/td&gt;
&lt;td&gt;6.28319&lt;/td&gt;
&lt;td&gt;1.9966e-6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-11&lt;/td&gt;
&lt;td&gt;6.28315&lt;/td&gt;
&lt;td&gt;3.35305e-5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-12&lt;/td&gt;
&lt;td&gt;6.28297&lt;/td&gt;
&lt;td&gt;0.000211166&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-13&lt;/td&gt;
&lt;td&gt;6.27054&lt;/td&gt;
&lt;td&gt;0.0126457&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-14&lt;/td&gt;
&lt;td&gt;6.39488&lt;/td&gt;
&lt;td&gt;0.111699&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-15&lt;/td&gt;
&lt;td&gt;5.32907&lt;/td&gt;
&lt;td&gt;0.954115&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.0e-16&lt;/td&gt;
&lt;td&gt;0.0&lt;/td&gt;
&lt;td&gt;6.28319&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;觀察最後一下發現, 當 $h$ 很小時微分竟然與真實質差更多, 更不準了!! 比如說當 $h=10^{-14}$ 時, 誤差竟然大到約是 $10^{-1}$.&lt;/p&gt;
&lt;p&gt;我們把它畫出來看看, &lt;code&gt;Julia&lt;/code&gt; code 如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-julia&#34; data-lang=&#34;julia&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;using&lt;/span&gt; Plots
plot(log10&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;(h), log10&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;(abs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;(fp&lt;span style=&#34;color:#f92672&#34;&gt;.-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;pi)),label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Error&amp;#34;&lt;/span&gt;)
xlabel!(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;log10(h)&amp;#34;&lt;/span&gt;)
ylabel!(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;log10(Error)&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;發現雖然誤差在 $h$ 大的時候遞減, 不過當 $h$ 接近零的時候卻又遞增上去了.&lt;/p&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://teshenglin.github.io/post/figs/2019_derivative_evaulate_01.svg&#34; &gt;


  &lt;img src=&#34;https://teshenglin.github.io/post/figs/2019_derivative_evaulate_01.svg&#34; alt=&#34;&#34; width=&#34;600px&#34; &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;那誤差最小值出現在什麼時候呢?&lt;/p&gt;
&lt;p&gt;我們發現當 當 $h=1.0*10^{-8}$ 時, 其估計出來的微分值離真實值誤差最小, 其誤差為 $4.26 *10^{-8}$.&lt;/p&gt;
&lt;p&gt;不過, WHY?? 為什麼誤差不會一直往下遞減? 其實這也是因為 &lt;strong&gt;捨入誤差(rounding-error)&lt;/strong&gt; 的關係.&lt;/p&gt;
&lt;p&gt;觀察一下我們的式子
$$
\frac{f(a+h)-f(a)}{h}
$$
當我們在用數值計算這個式子的時候其實並不完全是這樣子, 在分子應該會有捨入誤差在, 也就是說, 其實我們看到的數字應該是以下這個式子算出來的
$$
\frac{f(a+h)-f(a) + \epsilon}{h}
$$
其中的 $\epsilon$ 就是捨入誤差. 所以, 我們計算的時候會多出了 $\frac{\epsilon}{h}$ 這麼多.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;泰勒展開式&#34;&gt;泰勒展開式&lt;/h4&gt;
&lt;p&gt;再深一點來說, 我們可以利用泰勒展開式知道
$$
\frac{f(a+h)-f(a)}{h} = f&amp;rsquo;(a) + \frac{h}{2}f&amp;rsquo;&#39;(\xi), \quad a\leq \xi \leq a+h.
$$
這個式子告訴我們, 用這方式算微分誤差應該是 $\frac{h}{2}f&amp;rsquo;&#39;(\xi) = O(h)$, 誤差會隨著 $h$ 減少而線性變小.&lt;/p&gt;
&lt;p&gt;數學上我們有以上這個等式, 而數值計算上則是有以下這個等式
$$
\frac{f(a+h)-f(a) + \epsilon}{h} = f&amp;rsquo;(a) + \frac{h}{2}f&amp;rsquo;&#39;(\xi) + \frac{\epsilon}{h}, \quad a\leq \xi \leq a+h.
$$
也就是說, 真正的誤差公式應該是
$$
\frac{h}{2}f&amp;rsquo;&#39;(\xi) + \frac{\epsilon}{h},
$$
當 $h$ 非常小的時候 $\frac{\epsilon}{h}$ 這項就會變很大.&lt;/p&gt;
&lt;p&gt;比如說, 依我們之前所算的 $\epsilon\approx 10^{-16}$, 那當 $h=10^{-8}$ 時, 算出來的數字會多了大約 $\frac{10^{-16}}{10^{-8}} = 10^{-8}$.&lt;/p&gt;
&lt;p&gt;而當 $h=10^{-14}$ 時, 算出來的數字會多了大約 $\frac{10^{-16}}{10^{-14}} = 10^{-2}$. 跟我們之前所發現的完全吻合!! 而這也就是為什麼當 $h$ 很靠近零的時候誤差會上升的原因.&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;optimal-h&#34;&gt;Optimal $h$&lt;/h4&gt;
&lt;p&gt;那給定一個微分公式, 要怎麼知道 $h$ 能小到什麼程度呢? 一個簡單的感覺是這樣的, 由於誤差的第一項  $\frac{h}{2}f&amp;rsquo;&#39;(\xi)$ 會隨著 $h$ 變小而變小, 第二項 $\frac{\epsilon}{h}$ 則會變大, 因此整體最小值約會發生在兩項交叉時, 也就是當
$$
h \sim \frac{\epsilon}{h},
$$
(由於我們不知道 $f&amp;rsquo;&#39;(\xi)/2$ 是多少, 簡單起見設成 1). 上式稍微計算一下發現誤差最小值約發生在 $h=10^{-8}$, 誤差最小值則約為 $10^{-8}$.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary:&lt;/h3&gt;
&lt;p&gt;最後總結一下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;我們可以用數值計算來估計一個函數在某點的微分值
$$
f&amp;rsquo;(a) \approx \frac{f(a+h)-f(a)}{h}.
$$
這樣的做法稱為&lt;strong&gt;有限差分法 (finite difference method)&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不過計算時 $h$ 值不能無限取小, 需考慮到捨入誤差的影響.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>用電腦算極限</title>
      <link>https://teshenglin.github.io/post/2019_limit_evaluate/</link>
      <pubDate>Sun, 27 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://teshenglin.github.io/post/2019_limit_evaluate/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;這裡我們要介紹如何用電腦算極限, 以及我們來看一下當我們真的這樣做的時候有可能會發生什麼問題. 我們以 $sinc$ 函數為例來做說明.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;sinc-function&#34;&gt;sinc function&lt;/h3&gt;
&lt;p&gt;首先我們要介紹一個特別的函數, $sinc(x)$, 定義如下:
$$
sinc(x) = \frac{\sin(x)}{x}, \quad x\ne 0.
$$
很明顯可以看出來當 $x=0$ 的時候分母會等於零, 是一件壞事, 所以把 $x=0$ 這個點先拿掉.&lt;/p&gt;
&lt;p&gt;比較有趣的是我們可以把這個函數畫出來. 首先我們在 $[-20, 20]$ 這個區間取 $1000$ 個點, 然後帶入上面 $sinc$ 函數的定義, 再把所有點連起來看看.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; 有件事需要先說明一下, 由於我們是在 $[-20, 20]$ 這個區間均勻的取偶數個點, 所以會有 $500$ 個正數以及 $500$ 個負數, 重點是保證不會取到 $x=0$ 這個點, 所以沒有問題. 相反的, 如果取奇數個點就一定會取到 $x=0$, 那就會有函數無定義的問題了.&lt;/p&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://teshenglin.github.io/post/figs/output_3_0.svg&#34; &gt;


  &lt;img src=&#34;https://teshenglin.github.io/post/figs/output_3_0.svg&#34; alt=&#34;&#34; width=&#34;400px&#34; &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;我們很輕易可以看出來, 連起來的線還蠻&amp;quot;光滑&amp;quot;的. 函數值在 $x=0$ 附近似乎不會趨近正無窮大或負無窮大, 也沒有跳躍的現象. 接著我們試著在 $x=0$ 附近放大一點看看, 我們在 $[-0.1, 0.1]$ 這個區間取 $1000$ 個點, 然後帶入 $sinc$ 函數的定義再把它畫出來:&lt;/p&gt;















&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://teshenglin.github.io/post/figs/output_5_0.svg&#34; &gt;


  &lt;img src=&#34;https://teshenglin.github.io/post/figs/output_5_0.svg&#34; alt=&#34;&#34; width=&#34;400px&#34; &gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;看起來真的很光滑!! 而且似乎當 $x$ 很靠近 $0$ 時, $sinc(x)$ 的值很靠近 $1$.&lt;/p&gt;
&lt;p&gt;接著我們取一個會越來越靠近 $0$ 的數列, 然後看一下當把 $sinc$ 函數在這個數列的點上取值時, 其值會不會越來越靠近 $1$.  我們取以下數列:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; 1.670170079024566e-5
 6.14421235332821e-6
 2.2603294069810542e-6
 8.315287191035679e-7
 3.059023205018258e-7
 1.1253517471925912e-7
 4.139937718785167e-8
 1.522997974471263e-8
 5.602796437537268e-9
 2.061153622438558e-9
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;算一下 $sinc$ 函數在這些點上面的值, 並觀察他的趨勢:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; 0.9999999999535089
 0.9999999999937081
 0.9999999999991485
 0.9999999999998848
 0.9999999999999845
 0.9999999999999979
 0.9999999999999997
 1.0
 1.0
 1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;赫然發現算到後來就等於 $1$ 了!! 所以我們發現&lt;/p&gt;
&lt;p&gt;$$
\lim_{x\to 0} sinc(x) = \lim_{x\to 0} \frac{\sin(x)}{x} = 1.
$$&lt;/p&gt;
&lt;p&gt;不過有一點點詭異的是, 在剛剛的計算裡我們最多也只是取到離 $0$ 很近的點而已, 但是算出來的結果卻是 $1$. 難道不只是 $sinc(0)=1$, 我們也有 $sinc(2.061153622438558 *10^{-9})=1$ 嗎?&lt;/p&gt;
&lt;p&gt;事實上並不是這樣. 電腦有所謂的捨入誤差(rounding error). 這是因為電腦需要用有限位數來表達無窮小數, 所以一定要捨棄後面的位數. 我們把算出來的數字減去 $1$ 看看:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; -4.649114426769074e-11
 -6.291855925155687e-12
 -8.515410598874951e-13
 -1.1524114995609125e-13
 -1.554312234475219e-14
 -2.1094237467877974e-15
 -3.3306690738754696e-16
  0.0
  0.0
  0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我們可以發現這個數字最小可以到大約 $10^{-16}$, 之後就變成 $0$ 了. 也就是說我們目前用個這個程式語言其捨入誤差大約就是 $10^{-16}$.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;machine-epsilon&#34;&gt;machine epsilon&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;一般我們會用 machine epsilon 這個數字來量化在電腦裡浮點運算的捨入誤差.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;machine epsilon 的定義是, 考慮正數$\epsilon$, 使得 $ 1+ \epsilon \ge 1$ 中最小的那個稱之為 machine epsilon. 當然以數學來看這個 machine epsilon 必須等於零. 不過在電腦裡並不是這樣.&lt;/p&gt;
&lt;p&gt;為了方便我們稍微改一下定義, 我們考慮 $\epsilon = 2^{-k}$ 這種形式, 然後 machine epsilon 一樣是使得 $ 1+ \epsilon \ge 1$ 中最小的那個. &lt;code&gt;julia&lt;/code&gt; 程式如下:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-julia&#34; data-lang=&#34;julia&#34;&gt;s&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;
    s &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; s&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.0&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;s)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;
        s &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2.0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;s
        println(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k=&amp;#34;&lt;/span&gt;, k&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;,  eps=&amp;#34;&lt;/span&gt;, s)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在我的電腦上我發現 $\epsilon = 2^{-52} = 2.220446049250313e-16$.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;k=52,  eps=2.220446049250313e-16
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;所以的確捨入誤差大約是 $10^{-16}$ 這個等級.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;summary&#34;&gt;Summary:&lt;/h3&gt;
&lt;p&gt;稍微總結一下目前我們看到的:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;我們用程式跑數值發現 $sinc(x\to 0)=1$, 所以我們可以定義 sinc 函數為
$$
sinc(x) =
\begin{cases}
\frac{\sin(x)}{x}, \quad x\ne 0, \\\&lt;br&gt;
1, \quad x=0.
\end{cases}
$$
在這樣的定義之下 $sinc$ 函數是個&lt;code&gt;連續函數&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更多關於 $sinc$ 函數的性質可以參考 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Sinc_function&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wiki&lt;/a&gt; 上的介紹.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在數值計算上有所謂的捨入誤差, 這是用有限位元來表達無限位數一定會有的差異.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以用 machines epsilon 來量化捨入誤差.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
  </channel>
</rss>
